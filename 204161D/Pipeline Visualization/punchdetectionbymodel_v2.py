# -*- coding: utf-8 -*-
"""PunchDetectionByModel_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_F_dufGCb7Ngwkqi7I0q3IEUPXgeuVC6
"""

from google.colab import drive
import sys

# Mount Google Drive
drive.mount('/content/drive')

# Install necessary libraries
!{sys.executable} -m pip install ultralytics opencv-python pandas joblib scikit-learn -q

print("âœ… Setup complete.")

import cv2
from ultralytics import YOLO
import joblib

# --- 1. UPDATE YOUR FILE PATHS HERE ---
INPUT_VIDEO_PATH = '/content/drive/MyDrive/University/Research/Olympic Boxer dataset Adaptation/Visualize/Classification Model train/model visualize/input/highlight6.mp4'
OUTPUT_VIDEO_PATH = '/content/drive/MyDrive/University/Research/Olympic Boxer dataset Adaptation/Visualize/Classification Model train/model visualize/output/long Range/highlight6_out.mp4'
# Path to your trained commercial boxer detection model
PLAYER_MODEL_PATH = '/content/drive/MyDrive/University/Research/Olympic Boxer dataset Adaptation/Visualize/Classification Model train/model visualize/playerIdentificationModel2.pt'
# Path to your saved binary classification model
CLASSIFIER_MODEL_PATH = '/content/drive/MyDrive/University/Research/Olympic Boxer dataset Adaptation/Visualize/Classification Model train/model visualize/punch_classifier_model_binary_v2.joblib'


# --- 2. LOAD MODELS ---
try:
    player_model = YOLO(PLAYER_MODEL_PATH)
    print("âœ… Custom commercial player detection model loaded.")
except Exception as e:
    print(f"âŒ Error loading player model: {e}")
    sys.exit()

try:
    classifier_model = joblib.load(CLASSIFIER_MODEL_PATH)
    print("âœ… Punch classification model loaded.")
except Exception as e:
    print(f"âŒ Error loading classifier model: {e}")
    sys.exit()

pose_model = YOLO('yolov8n-pose.pt')
print("âœ… YOLOv8-Pose model loaded.")

import numpy as np
from collections import deque

# --- Keypoint Constants ---
R_WRIST, L_WRIST = 10, 9
R_SHOULDER, L_SHOULDER = 6, 5
R_ELBOW, L_ELBOW = 8, 7

def calculate_distance(p1, p2):
    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

def calculate_angle(p1, p2, p3):
    a, b, c = np.array(p1), np.array(p2), np.array(p3)
    ba, bc = a - b, c - b
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
    return np.degrees(np.arccos(cosine_angle))

def get_meters_per_pixel(kpts):
    AVG_SHOULDER_WIDTH_METERS = 0.45
    try:
        l_shoulder, r_shoulder = kpts[L_SHOULDER], kpts[R_SHOULDER]
        pixel_dist = calculate_distance(l_shoulder, r_shoulder)
        return AVG_SHOULDER_WIDTH_METERS / pixel_dist if pixel_dist > 0 else None
    except (IndexError, ZeroDivisionError):
        return None

# With full frameset annotation
from ultralytics.utils.plotting import Annotator
import pandas as pd
from collections import deque

# --- Video Processing Setup ---
cap = cv2.VideoCapture(INPUT_VIDEO_PATH)
if not cap.isOpened():
    print(f"âŒ FATAL ERROR: Could not open video file.")
else:
    print("âœ… Video file opened successfully. Starting punch detection...")
    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
    out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))

    # --- Data Structures & Parameters ---
    boxer_tracker, next_boxer_id, history, cooldowns = {}, 0, {}, {}
    WINDOW_SIZE = 15 # Using your specified window size
    PUNCH_COOLDOWN = int(fps / 2)
    print("Punch Cool Down: " + str(PUNCH_COOLDOWN))

    # --- NEW: Annotation Buffer ---
    active_annotations = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        new_tracker = {}
        annotator = Annotator(frame, line_width=2)

        # --- NEW: Draw from and manage the annotation buffer ---
        remaining_annotations = []
        for ann in active_annotations:
            annotator.text(ann['pos'], ann['text'], txt_color=(0, 0, 255))
            ann['duration'] -= 1
            if ann['duration'] > 0:
                remaining_annotations.append(ann)
        active_annotations = remaining_annotations

        for boxer_id in list(cooldowns.keys()):
            if cooldowns[boxer_id] > 0:
                cooldowns[boxer_id] -= 1

        player_results = player_model(frame, verbose=False, conf=0.4)
        detected_boxes = player_results[0].boxes.xyxy.cpu().numpy()

        # Tracking
        current_detections, assigned_ids = {i: None for i in range(len(detected_boxes))}, set()
        for boxer_id, last_center in boxer_tracker.items():
            min_dist, best_match_idx = 150, -1
            for i, box in enumerate(detected_boxes):
                if i in assigned_ids: continue
                center_x = (box[0] + box[2]) / 2
                dist = abs(center_x - last_center)
                if dist < min_dist:
                    min_dist, best_match_idx = dist, i
            if best_match_idx != -1:
                current_detections[best_match_idx], assigned_ids = boxer_id, assigned_ids | {best_match_idx}

        for i in range(len(detected_boxes)):
            if current_detections[i] is None:
                new_id = next_boxer_id
                current_detections[i] = new_id
                history[new_id] = {'left': deque(maxlen=WINDOW_SIZE), 'right': deque(maxlen=WINDOW_SIZE)}
                cooldowns[new_id], next_boxer_id = 0, next_boxer_id + 1

        # Process Each Boxer
        for i, boxer_id in current_detections.items():
            box = detected_boxes[i]
            x1, y1, x2, y2 = map(int, box)

            new_tracker[boxer_id] = (x1 + x2) / 2
            annotator.box_label(box, f'Boxer {boxer_id}', color=(0, 255, 0))

            cropped_boxer = frame[y1:y2, x1:x2]
            if cropped_boxer.size == 0: continue

            pose_results = pose_model(cropped_boxer, verbose=False)

            if len(pose_results) > 0 and pose_results[0].keypoints and len(pose_results[0].keypoints.data) > 0:
                kpts = pose_results[0].keypoints.data[0].cpu().numpy()
                kpts[:, 0], kpts[:, 1] = kpts[:, 0] + x1, kpts[:, 1] + y1
                annotator.kpts(kpts, shape=(h,w)) # Draw skeleton

                mpp = get_meters_per_pixel(kpts)
                if mpp is None: continue

                for side in ['left', 'right']:
                    try:
                        history[boxer_id][side].append({'wrist': kpts[L_WRIST if side == 'left' else R_WRIST], 'elbow': kpts[L_ELBOW if side == 'left' else R_ELBOW], 'shoulder': kpts[L_SHOULDER if side == 'left' else R_SHOULDER]})
                    except IndexError: continue

                    if len(history[boxer_id][side]) == WINDOW_SIZE and cooldowns.get(boxer_id, 0) == 0:
                        wrist_positions = [h['wrist'][:2] for h in history[boxer_id][side]]
                        velocities = [(calculate_distance(wrist_positions[i], wrist_positions[i-1]) * mpp) * fps for i in range(1, len(wrist_positions))]
                        if not velocities: continue

                        accelerations = [(velocities[i] - velocities[i-1]) * fps for i in range(1, len(velocities))]
                        if not accelerations: accelerations = [0]

                        angles = [calculate_angle(h['shoulder'][:2], h['elbow'][:2], h['wrist'][:2]) for h in history[boxer_id][side]]

                        peak_velocity_idx = np.argmax(velocities)

                        features = {
                            'peak_velocity': max(velocities), 'mean_velocity': np.mean(velocities),
                            'std_velocity': np.std(velocities), 'peak_acceleration': max(accelerations),
                            'mean_acceleration': np.mean(accelerations),
                            'angle_at_peak': angles[peak_velocity_idx + 1] if peak_velocity_idx + 1 < len(angles) else angles[-1],
                            'mean_angle': np.mean(angles),
                            'total_displacement': calculate_distance(wrist_positions[0], wrist_positions[-1]) * mpp,
                        }

                        features_df = pd.DataFrame([features])
                        prediction_encoded = classifier_model.predict(features_df)[0]

                        if prediction_encoded == 1:
                            wrist_pos = history[boxer_id][side][-1]['wrist']
                            # --- NEW: Add detection to the buffer instead of drawing directly ---
                            active_annotations.append({
                                'text': 'PUNCH',
                                'pos': tuple(map(int, wrist_pos[:2])),
                                'duration': WINDOW_SIZE # Set the duration
                            })
                            cooldowns[boxer_id] = PUNCH_COOLDOWN
                            history[boxer_id][side].clear()

        boxer_tracker = new_tracker
        final_frame = annotator.im
        out.write(final_frame)

    cap.release()
    out.release()
    print(f"ðŸŽ‰ Detection complete! Output video saved to: {OUTPUT_VIDEO_PATH}")

"""# With Rules to reduce False Positives"""

from ultralytics.utils.plotting import Annotator
import pandas as pd
from collections import deque

# --- New Helper Function to Find the Opponent ---
def get_opponent_id(puncher_id, tracked_boxers):
    """Finds the ID of the opponent."""
    for boxer_id in tracked_boxers:
        if boxer_id != puncher_id:
            return boxer_id
    return None

# --- Video Processing Setup ---
cap = cv2.VideoCapture(INPUT_VIDEO_PATH)
if not cap.isOpened():
    print(f"âŒ FATAL ERROR: Could not open video file.")
else:
    print("âœ… Video file opened successfully. Starting punch detection...")
    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))
    out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))

    # --- Data Structures & Parameters ---
    boxer_tracker, next_boxer_id, history, cooldowns = {}, 0, {}, {}
    WINDOW_SIZE = 15
    PUNCH_COOLDOWN = int(fps / 2)
    active_annotations = []

    # Store the full keypoints for each boxer in each frame for the proximity check
    frame_keypoints = {}

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break

        new_tracker = {}
        annotator = Annotator(frame, line_width=2)

        # --- Annotation Buffer Logic ---
        remaining_annotations = []
        for ann in active_annotations:
            annotator.text(ann['pos'], ann['text'], txt_color=(0, 0, 255))
            ann['duration'] -= 1
            if ann['duration'] > 0:
                remaining_annotations.append(ann)
        active_annotations = remaining_annotations

        for boxer_id in list(cooldowns.keys()):
            if cooldowns[boxer_id] > 0:
                cooldowns[boxer_id] -= 1

        player_results = player_model(frame, verbose=False, conf=0.4)
        detected_boxes = player_results[0].boxes.xyxy.cpu().numpy()

        # --- Tracking ---
        current_detections, assigned_ids = {i: None for i in range(len(detected_boxes))}, set()
        for boxer_id, last_center in boxer_tracker.items():
            min_dist, best_match_idx = 150, -1
            for i, box in enumerate(detected_boxes):
                if i in assigned_ids: continue
                center_x = (box[0] + box[2]) / 2
                dist = abs(center_x - last_center)
                if dist < min_dist:
                    min_dist, best_match_idx = dist, i
            if best_match_idx != -1:
                current_detections[best_match_idx], assigned_ids = boxer_id, assigned_ids | {best_match_idx}

        for i in range(len(detected_boxes)):
            if current_detections[i] is None:
                new_id = next_boxer_id
                current_detections[i] = new_id
                history[new_id] = {'left': deque(maxlen=WINDOW_SIZE), 'right': deque(maxlen=WINDOW_SIZE)}
                cooldowns[new_id], next_boxer_id = 0, next_boxer_id + 1

        # --- Process Each Boxer ---
        current_frame_kpts = {}
        for i, boxer_id in current_detections.items():
            box = detected_boxes[i]
            x1, y1, x2, y2 = map(int, box)

            new_tracker[boxer_id] = (x1 + x2) / 2
            annotator.box_label(box, f'Boxer {boxer_id}', color=(0, 255, 0))

            cropped_boxer = frame[y1:y2, x1:x2]
            if cropped_boxer.size == 0: continue

            pose_results = pose_model(cropped_boxer, verbose=False)

            if len(pose_results) > 0 and pose_results[0].keypoints and len(pose_results[0].keypoints.data) > 0:
                kpts = pose_results[0].keypoints.data[0].cpu().numpy()
                kpts[:, 0], kpts[:, 1] = kpts[:, 0] + x1, kpts[:, 1] + y1
                annotator.kpts(kpts, shape=(h,w))

                # Store keypoints for this frame for the proximity check
                current_frame_kpts[boxer_id] = kpts

                mpp = get_meters_per_pixel(kpts)
                if mpp is None: continue

                for side in ['left', 'right']:
                    try:
                        history[boxer_id][side].append({'wrist': kpts[L_WRIST if side == 'left' else R_WRIST], 'elbow': kpts[L_ELBOW if side == 'left' else R_ELBOW], 'shoulder': kpts[L_SHOULDER if side == 'left' else R_SHOULDER]})
                    except IndexError: continue

                    if len(history[boxer_id][side]) == WINDOW_SIZE and cooldowns.get(boxer_id, 0) == 0:
                        # (Feature calculation logic is the same...)
                        wrist_positions = [h['wrist'][:2] for h in history[boxer_id][side]]
                        velocities = [(calculate_distance(wrist_positions[i], wrist_positions[i-1]) * mpp) * fps for i in range(1, len(wrist_positions))]
                        if not velocities: continue
                        accelerations = [(velocities[i] - velocities[i-1]) * fps for i in range(1, len(velocities))]
                        if not accelerations: accelerations = [0]
                        angles = [calculate_angle(h['shoulder'][:2], h['elbow'][:2], h['wrist'][:2]) for h in history[boxer_id][side]]
                        peak_velocity_idx = np.argmax(velocities)
                        features = {
                            'peak_velocity': max(velocities), 'mean_velocity': np.mean(velocities),
                            'std_velocity': np.std(velocities), 'peak_acceleration': max(accelerations),
                            'mean_acceleration': np.mean(accelerations),
                            'angle_at_peak': angles[peak_velocity_idx + 1] if peak_velocity_idx + 1 < len(angles) else angles[-1],
                            'mean_angle': np.mean(angles),
                            'total_displacement': calculate_distance(wrist_positions[0], wrist_positions[-1]) * mpp,
                        }

                        features_df = pd.DataFrame([features])
                        prediction_encoded = classifier_model.predict(features_df)[0]

                        if prediction_encoded == 1:
                            # --- NEW: Proximity Verification Step ---
                            is_a_confirmed_punch = False

                            opponent_id = get_opponent_id(boxer_id, new_tracker.keys())

                            # Check if opponent exists and has keypoints
                            if opponent_id is not None and opponent_id in current_frame_kpts:
                                puncher_hand_pos = history[boxer_id][side][peak_velocity_idx]['wrist'][:2]
                                opponent_kpts = current_frame_kpts[opponent_id]

                                try:
                                    # Define opponent's torso
                                    opp_l_shoulder = opponent_kpts[L_SHOULDER][:2]
                                    opp_r_shoulder = opponent_kpts[R_SHOULDER][:2]

                                    # Simple target: the midpoint of the opponent's shoulders
                                    opponent_target_pos = (opp_l_shoulder + opp_r_shoulder) / 2

                                    # Calculate the relative threshold
                                    opponent_shoulder_width = calculate_distance(opp_l_shoulder, opp_r_shoulder)
                                    distance_threshold = opponent_shoulder_width * 1.5 # Allow some margin

                                    # Measure the distance
                                    distance_to_target = calculate_distance(puncher_hand_pos, opponent_target_pos)

                                    if distance_to_target < distance_threshold:
                                        is_a_confirmed_punch = True

                                except IndexError:
                                    # If opponent's keypoints are missing, trust the model (Option A)
                                    is_a_confirmed_punch = True
                            else:
                                # If we can't find an opponent, trust the model (Option A)
                                is_a_confirmed_punch = True

                            if is_a_confirmed_punch:
                                wrist_pos = history[boxer_id][side][-1]['wrist']
                                active_annotations.append({
                                    'text': 'PUNCH',
                                    'pos': tuple(map(int, wrist_pos[:2])),
                                    'duration': WINDOW_SIZE
                                })
                                cooldowns[boxer_id] = PUNCH_COOLDOWN
                                history[boxer_id][side].clear()

        boxer_tracker = new_tracker
        final_frame = annotator.im
        out.write(final_frame)

    cap.release()
    out.release()
    print(f"ðŸŽ‰ Detection complete! Output video saved to: {OUTPUT_VIDEO_PATH}")