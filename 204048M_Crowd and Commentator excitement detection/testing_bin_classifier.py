# -*- coding: utf-8 -*-
"""testing_bin_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zA-38zIG1RZ7St_HA3w7ZJ_bqFMnZbE0
"""

# --- Import libraries ---
import librosa
import numpy as np
import soundfile as sf
import joblib
from google.colab import files
import os

# --- Helper function for feature extraction (must match training) ---
def extract_bin_features_for_frame(magnitude_frame, freqs):
    features = []
    num_freq_bins = len(magnitude_frame)
    for f in range(num_freq_bins):
        mag_val = magnitude_frame[f]
        freq_val = freqs[f]
        v_neighbors = magnitude_frame[max(0, f-1):min(num_freq_bins, f+2)]
        v_mean = np.mean(v_neighbors)
        features.append([mag_val, freq_val, v_mean, v_mean])
    return np.array(features)

# --- Main Separation Algorithm ---
def run_separation_algorithm():
    # 1. Load your trained "knowledge base"
    print("--- Step 1: Uploading Your Trained Bin Classifier ---")
    print("Please upload your 'bin_classifier.pkl' and 'bin_scaler.pkl' files.")
    try:
        uploaded_models = files.upload()
        if 'bin_classifier.pkl' not in uploaded_models or 'bin_scaler.pkl' not in uploaded_models:
             print("\n❌ Error: Make sure you upload BOTH files.")
             return
        model = joblib.load('bin_classifier.pkl')
        scaler = joblib.load('bin_scaler.pkl')
        print("✅ Model and scaler loaded successfully.")
    except Exception as e:
        print(f"Error: {e}")
        return

    # 2. Upload the mixed audio file you want to separate
    print("\n--- Step 2: Uploading Mixed Audio ---")
    print("Please upload the mixed audio file you want to separate.")
    uploaded_audio = files.upload()
    if not uploaded_audio:
        print("No audio file uploaded. Exiting.")
        return

    filename = next(iter(uploaded_audio))
    with open(filename, 'wb') as f:
        f.write(uploaded_audio[filename])

    # 3. Perform the Separation
    print(f"\n--- Step 3: Separating '{filename}'... (This may take a moment) ---")
    SAMPLE_RATE = 16000
    N_FFT = 1024
    HOP_LENGTH = 512

    audio, sr = librosa.load(filename, sr=SAMPLE_RATE, mono=True)
    stft_mixed = librosa.stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH)
    mag_mixed, phase_mixed = np.abs(stft_mixed), np.angle(stft_mixed)

    speech_mask = np.zeros_like(mag_mixed)
    speech_class_index = np.where(model.classes_ == 'commentator_only')[0][0]

    freqs = librosa.fft_frequencies(sr=sr, n_fft=N_FFT)
    for t in range(mag_mixed.shape[1]):
        frame_features = extract_bin_features_for_frame(mag_mixed[:, t], freqs)
        frame_features_scaled = scaler.transform(frame_features)
        frame_probs = model.predict_proba(frame_features_scaled)
        speech_mask[:, t] = frame_probs[:, speech_class_index]

    crowd_mask = 1 - speech_mask

    mag_speech = mag_mixed * speech_mask
    mag_crowd = mag_mixed * crowd_mask

    audio_speech = librosa.istft(mag_speech * np.exp(1j * phase_mixed), hop_length=HOP_LENGTH)
    audio_crowd = librosa.istft(mag_crowd * np.exp(1j * phase_mixed), hop_length=HOP_LENGTH)

    print("\n--- Step 4: Saving and Downloading Results ---")
    sf.write('separated_commentator.wav', audio_speech, SAMPLE_RATE)
    sf.write('separated_crowd.wav', audio_crowd, SAMPLE_RATE)

    print("✅ Separation complete. Downloading your two separated audio files...")
    files.download('separated_commentator.wav')
    files.download('separated_crowd.wav')

# --- Run the algorithm ---
run_separation_algorithm()