# -*- coding: utf-8 -*-
"""Test Crowd Excitement CNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZU-F2GM_eXH_537opRWwuw3dCEInuE2F
"""

# ===================================================================
# SCRIPT: Test Your Trained Crowd Excitement CNN Model
# ===================================================================
#
# Instructions:
# 1. Run this cell in a NEW Colab notebook.
# 2. It will first ask you to upload your trained 'crowd_cnn_binary.keras' model file.
# 3. Then, it will ask for the audio file you want to test.
# 4. The script will analyze the audio and print a timestamped timeline
#    of its excitement predictions.
#
# ===================================================================

# --- 1. Install and import libraries ---
!pip install librosa matplotlib tensorflow -q

import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
import os
import tensorflow as tf

# --- 2. Helper function to create spectrograms (MUST MATCH TRAINING SCRIPT) ---
def create_mel_spectrogram_image(audio_chunk, sr):
    """
    Creates a Mel spectrogram image from an audio chunk, ready for the CNN.
    """
    try:
        # Generate spectrogram using the same parameters as training
        S = librosa.feature.melspectrogram(y=audio_chunk, sr=sr, n_mels=128, fmax=8000)
        S_DB = librosa.power_to_db(S, ref=np.max)

        # --- Data Preparation for the CNN ---
        # Normalize the image data to be between 0 and 1
        img_normalized = (S_DB - np.min(S_DB)) / (np.max(S_DB) - np.min(S_DB) + 1e-6)

        # Convert to a 3-channel image to match model input
        img_rgb = np.stack([img_normalized, img_normalized, img_normalized], axis=-1)

        # Resize to the standard input size for the model
        img_tensor = tf.convert_to_tensor(img_rgb, dtype=tf.float32)
        img_resized = tf.image.resize(img_tensor, [224, 224])

        # Add a batch dimension
        img_batch = np.expand_dims(img_resized, axis=0)

        return img_batch

    except Exception as e:
        print(f"Error creating spectrogram: {e}")
        return None

# --- 3. Main testing script ---
def test_crowd_model():
    # --- Upload the trained model ---
    print("--- Please upload your trained 'crowd_cnn_binary.keras' model file ---")
    uploaded = files.upload()
    if not uploaded:
        print("No model file uploaded. Exiting.")
        return

    model_path = next(iter(uploaded))
    try:
        model = tf.keras.models.load_model(model_path)
        print("✅ Model loaded successfully.")
    except Exception as e:
        print(f"❌ Error loading model: {e}")
        return

    # --- Upload the audio to test ---
    print("\n--- Please upload the audio file you want to test ---")
    uploaded_audio = files.upload()
    if not uploaded_audio:
        print("No audio file uploaded. Exiting.")
        return

    audio_path = next(iter(uploaded_audio))
    with open('temp_audio_test.wav', 'wb') as f:
        f.write(uploaded_audio[audio_path])

    # --- Process the audio and predict ---
    print(f"\n--- Analyzing '{audio_path}' ---")
    sample_rate = 22050
    chunk_duration = 1.0
    class_names = ['excited', 'not_excited'] # IMPORTANT: Must match the order from training

    try:
        y, sr = librosa.load('temp_audio_test.wav', sr=sample_rate)
        total_duration = librosa.get_duration(y=y, sr=sr)
        num_chunks = int(total_duration // chunk_duration)

        print("\nPrediction Timeline:")
        print("-" * 40)
        for i in range(num_chunks):
            start_time = i * chunk_duration
            end_time = (i + 1) * chunk_duration

            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            chunk = y[start_sample:end_sample]

            # Create spectrogram image for the chunk
            spec_image = create_mel_spectrogram_image(chunk, sr)

            if spec_image is not None:
                # Make a prediction
                prediction = model.predict(spec_image, verbose=0)
                predicted_class_index = np.argmax(prediction)
                predicted_class_name = class_names[predicted_class_index]
                confidence = np.max(prediction) * 100

                print(f"Time: {start_time:.2f}s - {end_time:.2f}s  ->  Predicted: {predicted_class_name} ({confidence:.1f}%)")

        print("-" * 40)

    except Exception as e:
        print(f"Could not process audio file: {e}")

# --- Run the testing process ---
test_crowd_model()