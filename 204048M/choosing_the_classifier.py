# -*- coding: utf-8 -*-
"""choosing the classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CUPzkBtUP6NKfe9LXPbr3O20Us0dOCrR
"""

# --- Step 1: Import necessary libraries ---
import pandas as pd
import numpy as np
from google.colab import files
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# --- Step 2: Upload and Load the Dataset ---
print("Please upload your 'features.csv' file from the 'classifier_dataset.zip'.")
uploaded = files.upload()

# Check if a file was uploaded and load it
if uploaded:
    # Get the filename of the uploaded file
    filename = next(iter(uploaded))
    print(f"\nLoading '{filename}'...")
    df = pd.read_csv(filename)

    # --- Step 3: Prepare Data for Training ---
    print("Preparing data...")
    # Separate features (X) from the target label (y)
    X = df.drop('class_label', axis=1)
    y = df['class_label']

    # Split the data into training (80%) and testing (20%) sets
    # stratify=y ensures that the class distribution is the same in train and test sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # Scale the features. This is important for SVMs.
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print("Data preparation complete.")

    # --- Step 4: Train and Evaluate Model 1: Support Vector Machine (SVM) ---
    print("\n--- Training Model 1: Support Vector Machine (SVM) ---")
    # Initialize the SVM classifier
    svm_model = SVC(kernel='rbf', C=1.0, random_state=42)

    # Train the model
    svm_model.fit(X_train_scaled, y_train)
    print("SVM model trained.")

    # Make predictions on the test set
    y_pred_svm = svm_model.predict(X_test_scaled)

    # Evaluate the model
    print("\nSVM Performance Evaluation:")
    print(classification_report(y_test, y_pred_svm))

    # Display the Confusion Matrix
    print("SVM Confusion Matrix:")
    cm_svm = confusion_matrix(y_test, y_pred_svm)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=svm_model.classes_, yticklabels=svm_model.classes_)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('SVM Confusion Matrix')
    plt.show()


    # --- Step 5: Train and Evaluate Model 2: Random Forest ---
    print("\n--- Training Model 2: Random Forest ---")
    # Initialize the Random Forest classifier
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

    # Train the model
    rf_model.fit(X_train_scaled, y_train)
    print("Random Forest model trained.")

    # Make predictions on the test set
    y_pred_rf = rf_model.predict(X_test_scaled)

    # Evaluate the model
    print("\nRandom Forest Performance Evaluation:")
    print(classification_report(y_test, y_pred_rf))

    # Display the Confusion Matrix
    print("Random Forest Confusion Matrix:")
    cm_rf = confusion_matrix(y_test, y_pred_rf)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=rf_model.classes_, yticklabels=rf_model.classes_)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Random Forest Confusion Matrix')
    plt.show()

else:
    print("No file uploaded. Please run the cell again and upload your features.csv file.")

# Add this to the end of your training code cell
import joblib

# Save the SVM model
joblib.dump(svm_model, 'svm_classifier.pkl')

# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

print("\nSVM Model and Scaler have been saved!")